{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_knrNHXGl91k"
      },
      "source": [
        "Preprocessing images into PATCH_SIZE patches with OVERLAP.\n",
        "Saving into npz file containing train,val, test images.\n",
        "\n",
        "Last updated: 07.06\n",
        "\n",
        "Change: patch size 256, only taking first 11 depths to standardize input.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCz6M7fo1Bdm"
      },
      "outputs": [],
      "source": [
        "# !pip install tifffile\n",
        "# !pip install sklearn\n",
        "# !pip install scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0znPRdBWGba"
      },
      "outputs": [],
      "source": [
        "# Constant values\n",
        "IMG_SIZE = 512\n",
        "OVERLAP = 0\n",
        "PATCH_SIZE = 512\n",
        "TYPES = ['NADH'] # up to 3 types: NADH, FAD, SDG\n",
        "MAIN_PATH = r\"/content/drive/MyDrive/Research and Grad/Diamond Program/objective_transfer\"\n",
        "NPZ_VER = \"_3depths_3D\" # version of data split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMUT7spjl35_"
      },
      "outputs": [],
      "source": [
        "# importing dependencies\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import sklearn.model_selection\n",
        "import skimage\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import psutil\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open drive dynamically; prefer drives that have 'drive' in their name.\n",
        "MAIN_DIR= r\"/content/drive/MyDrive/Research and Grad/Diamond Program/objective_transfer/deep_learning\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(MAIN_DIR+'/CAREstd/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EH84DcbLbtZ",
        "outputId": "dcfaa7e1-930e-4201-becb-77483694cb05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dm9i9E7B_hTq"
      },
      "outputs": [],
      "source": [
        "def SoundNotification():\n",
        "    global sound\n",
        "    sr = 22050 # sample rate\n",
        "    T = 0.5    # seconds\n",
        "    t = np.linspace(0, T, int(T*sr), endpoint=False) # time variable\n",
        "    x = 0.5*np.sin(2*np.pi*440*t)              # pure sine wave at 440 Hz\n",
        "    sound = ipd.Audio(x, rate=sr, autoplay=True) # load a NumPy array\n",
        "\n",
        "    return sound\n",
        "\n",
        "def WhereIWantToUseTheSound():\n",
        "    sound = SoundNotification()\n",
        "    return sound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDm7CwKP5lHg"
      },
      "outputs": [],
      "source": [
        "from functools import wraps\n",
        "import time\n",
        "\n",
        "\n",
        "def timeit(func):\n",
        "    @wraps(func)\n",
        "    def timeit_wrapper(*args, **kwargs):\n",
        "        start_time = time.perf_counter()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = time.perf_counter()\n",
        "        total_time = end_time - start_time\n",
        "        print(f'Function {func.__name__}{args} {kwargs} Took {total_time:.4f} seconds')\n",
        "        return result\n",
        "    return timeit_wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7w2v2D5Gsxz"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_patches(img, patch_shape, slide):\n",
        "  # returns stack of patches and number of patches\n",
        "  patch_img = skimage.util.view_as_windows(img, (patch_shape,patch_shape), step=patch_shape-slide)\n",
        "  # # stacking patches\n",
        "  # patch = np.zeros((patch_img.shape[0]*patch_img.shape[1],patch_shape,patch_shape))\n",
        "  # # creating 3D array by stacking patches by rows\n",
        "  # for row in range(patch_img.shape[0]):\n",
        "  #     start = row*patch_img.shape[1]\n",
        "  #     end = row*patch_img.shape[1]+patch_img.shape[1]\n",
        "  #     patch[row*patch_img.shape[1]:row*patch_img.shape[1]+patch_img.shape[1],:,:] = patch_img[row, :, :,:]\n",
        "  patch = patch_img.reshape(patch_img.shape[0]*patch_img.shape[1],patch_shape,patch_shape) # more time efficient\n",
        "  return patch\n",
        "\n",
        "def merge_patches(img, patch_shape, slide):\n",
        "  #  merging patches\n",
        "  row_len = int(math.sqrt(img.shape[0]))\n",
        "  patches = np.zeros((row_len,row_len,patch_shape,patch_shape))\n",
        "  print(patches.shape)\n",
        "  for r in range(row_len):\n",
        "      patches[r,:,:,:] = img[r*row_len:r*row_len+row_len,:,:]\n",
        "  plt.figure(5)\n",
        "  plt.imshow(patches[1,1,:,:])\n",
        "  return revert_img(patches,patch_shape, slide)\n",
        "\n",
        "def revert_img(img, patch_shape, slide):\n",
        "  # reverts original image and removes overlaps by splitting overlap over 2 images\n",
        "  step = int(patch_shape-slide)\n",
        "  reconstructed_arr = np.zeros((1024,1024))\n",
        "  for x in range(img.shape[0]):\n",
        "    for y in range(img.shape[1]):\n",
        "      start_x = int(slide/2)\n",
        "      start_y = int(slide/2)\n",
        "      end_x = 0\n",
        "      end_y = 0\n",
        "      if x == 0:\n",
        "        start_x = 0\n",
        "        end_x = int(slide/2)\n",
        "      if y == 0:\n",
        "        start_y = 0\n",
        "        end_y = int(slide/2)\n",
        "      if x == img.shape[0]-1: end_x = int(slide/2)\n",
        "      if y == img.shape[1]-1: end_y = int(slide/2)\n",
        "      x_pos, y_pos = x * step + start_x, y * step + start_y\n",
        "      print(x, y, )\n",
        "      reconstructed_arr[x_pos : x_pos + step + end_x, y_pos : y_pos + step + end_y] = img[x, y, start_x:start_x+step+end_x, start_y:start_y+step+end_y]\n",
        "  return reconstructed_arr\n",
        "\n",
        "def normalize(img):\n",
        "  # Normalizing images between 0 and 1\n",
        "  # img = img - img.min()\n",
        "  # img = np.divide(img, img.max())\n",
        "  # Normalizing images between 0 and 1 and preserving distribution\n",
        "  img_norm = (img - np.amin(img))/( np.amax(img)- np.amin(img))\n",
        "  return img_norm\n",
        "\n",
        "def normalize_percentile(img, pmin=1, pmax=99.9, clip = False):\n",
        "  eps=1e-20 # avoid zero division\n",
        "  mi = np.percentile(img,pmin,axis=None,keepdims=True)\n",
        "  # mi = np.amin(img)\n",
        "  # print(\"mi\",mi)\n",
        "  ma = np.percentile(img,pmax,axis=None,keepdims=True)\n",
        "  if clip == True: return np.clip((img - mi) / ( ma - mi + eps ), 0, 1)\n",
        "  return (img - mi) / ( ma - mi + eps )\n",
        "\n",
        "def concatenate(A,B):\n",
        "  return np.concatenate((A,B)) if len(A)>0 else B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0OnczI4l38H"
      },
      "outputs": [],
      "source": [
        "# PREPROCESSING\n",
        "# normalizing, splitting into patches, and then returning data, label arrays\n",
        "def preprocess(ddict, patch_size, patch_overlap, types=['NADH'], process=\"up\"):\n",
        "  len_to_allocate = 0\n",
        "  # getting number of input images\n",
        "  for key in types:\n",
        "    len_to_allocate = np.array(ddict['25X'][key]).shape[0]\n",
        "  len_to_allocate = int(len_to_allocate*((patch_overlap-IMG_SIZE) / (patch_overlap-patch_size))**2)\n",
        "  data = np.empty((len_to_allocate,patch_size,patch_size))\n",
        "  labels = np.empty((len_to_allocate,patch_size,patch_size))\n",
        "  count = 0\n",
        "  for key in types:\n",
        "    num_depths = np.asarray(ddict['25X'][key]).shape[0] # number of images/depths\n",
        "    # for every 2D image/every depth\n",
        "    for i in range(num_depths):\n",
        "        # print(\"i: \",i)\n",
        "        # Generating image patches with overlaps with chosen patch sizes and normalize\n",
        "        # if not patchifying, img size == patch size\n",
        "        if patch_size == IMG_SIZE:\n",
        "          A = normalize_percentile(ddict['25X'][key][i, :, :])\n",
        "          B = normalize_percentile(ddict['40X'][key][i, :, :])\n",
        "        else:\n",
        "          A = create_patches(normalize_percentile(ddict['25X'][key][i, :, :]), patch_size, patch_overlap)\n",
        "          B = create_patches(normalize_percentile(ddict['40X'][key][i, :, :]), patch_size, patch_overlap)\n",
        "        # appending, depending whether we are upscaling or downscaling\n",
        "        if process==\"down\":\n",
        "          C = A\n",
        "          A = B\n",
        "          B = C\n",
        "        data[count:count+len(A),:,:] = A[:,:,:]\n",
        "        del A # save memory\n",
        "        labels[count:count+len(B),:,:] = B[:,:,:]\n",
        "        count = count + len(B)\n",
        "  return [data, labels]\n",
        "\n",
        "def preprocess_stack(ddict,stack_name, patch_size, patch_overlap, types=['NADH'], process=\"up\"):\n",
        "  len_to_allocate = 0\n",
        "  # getting number of input images\n",
        "  for key in types:\n",
        "    len_to_allocate += np.array(ddict['25X'][key][stack_name]).shape[2]\n",
        "  len_to_allocate = int(len_to_allocate*((patch_overlap-IMG_SIZE) / (patch_overlap-patch_size))**2)\n",
        "  data = np.empty((len_to_allocate,patch_size,patch_size))\n",
        "  labels = np.empty((len_to_allocate,patch_size,patch_size))\n",
        "  count = 0\n",
        "  print(\"shape of data\", np.shape(data))\n",
        "  for key in types:\n",
        "    # for every 2D image/every depth\n",
        "    for i in range(np.array(ddict['25X'][key][stack_name]).shape[2]-1):\n",
        "        # print(\"i: \",i)\n",
        "        # Generating image patches with overlaps with chosen patch sizes and normalize\n",
        "        A = create_patches(normalize_percentile(ddict['25X'][key][stack_name][:, :, i], 1, 99.9, clip=True), patch_size, patch_overlap)\n",
        "        B = create_patches(normalize_percentile(ddict['40X'][key][stack_name][:, :, i], 1, 99.9, clip=True), patch_size, patch_overlap)\n",
        "        # appending, depending whether we are upscaling or downscaling\n",
        "        if process==\"down\":\n",
        "          C = A\n",
        "          A = B\n",
        "          B = C\n",
        "        data[count:count+len(A),:,:] = A[:,:,:]\n",
        "        del A # save memory\n",
        "        labels[count:count+len(B),:,:] = B[:,:,:]\n",
        "        count = count + len(B)\n",
        "  return [data, labels]\n",
        "\n",
        "def preprocess3D(ddict,stack_name, patch_size, patch_overlap, types=['NADH'], process=\"up\"):\n",
        "   # generating 4D arrays of patches over depths with the shape [patches, patch size, patch size, depths]\n",
        "    depths = NUM_OF_DEPTHS\n",
        "    len_to_allocate = int(((patch_overlap-IMG_SIZE) / (patch_overlap-patch_size))**2)\n",
        "    data = np.empty((len_to_allocate,patch_size,patch_size,depths-1))\n",
        "    labels = np.empty((len_to_allocate,patch_size,patch_size,depths-1))\n",
        "    for key in types:\n",
        "      # for every 2D image/every depth\n",
        "      for i in range(depths-1):\n",
        "          # print(\"min(depths)-1: \",min(depths)-1, \" shape: \", np.shape(ddict['25X'][key][stack_name][:, :, i]))\n",
        "          # Generating image patches with overlaps with chosen patch sizes and normalize\n",
        "          A = create_patches(normalize_percentile(ddict['25X'][key][stack_name][:, :, i]), patch_size, patch_overlap)\n",
        "          B = create_patches(normalize_percentile(ddict['40X'][key][stack_name][:, :, i]), patch_size, patch_overlap)\n",
        "          # appending, depending whether we are upscaling or downscaling\n",
        "          if process==\"down\":\n",
        "            C = A\n",
        "            A = B\n",
        "            B = C\n",
        "          data[:,:,:,i] = A[:,:,:]\n",
        "          del A # save memory\n",
        "          labels[:,:,:,i] = B[:,:,:]\n",
        "    return [data, labels]\n",
        "\n",
        "def preprocess3D_fullsize_3_depths(ddict,stack_name, types='NADH', process=\"up\"):\n",
        "    # loading and normalizing stacks of train and label data, no 2D patchifying\n",
        "    # return array of 3D stacks of 3 consecutive depths\n",
        "    shape = np.shape(ddict['25X'][types][stack_name])\n",
        "    print(\"Stack shape: \", shape,stack_name)\n",
        "    depths = shape[-1]\n",
        "    data = []\n",
        "    labels = []\n",
        "    # we will ignore first depth, start at 2nd depth and create 3D stack of previous,current, and next depth\n",
        "    for i in range(1,depths-1):\n",
        "      # creating 3depth stack\n",
        "      A = ddict['25X'][types][stack_name][:, :, i-1:i+2]\n",
        "      B = ddict['40X'][types][stack_name][:, :, i-1:i+2]\n",
        "      # normalizing each depth 0 to 1\n",
        "      for j in range(3):\n",
        "        A[:,:,j] = normalize_percentile(A[:,:,j])\n",
        "        B[:,:,j] = normalize_percentile(B[:,:,j])\n",
        "      # appending, depending whether we are upscaling or downscaling\n",
        "      if process==\"down\":\n",
        "        C = A\n",
        "        A = B\n",
        "        B = C\n",
        "      data = [A] if len(data) == 0 else np.concatenate((data,[A]))\n",
        "      labels = [B] if len(labels) == 0 else np.concatenate((labels,[B]))\n",
        "    print(\"SHAPE DATA: \", np.shape(data),stack_name)\n",
        "    return [data, labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amOXPFaOl38G",
        "outputId": "23f3178d-b008-42b7-a7b4-bcb592635bec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['20210420_ROI2_512_shifted.mat', '20210420_ROI3_512_shifted.mat', '20210421_ROI4_512_shifted.mat', '20210421_ROI5_512_shifted.mat', '20210426_ROI1_512_shifted.mat', '20210426_ROI2_512_shifted.mat', '20210426_ROI3_512_shifted.mat', '20210426_ROI4_512_shifted.mat', '20210505_ROI1_512_shifted.mat', '20210505_ROI2_512_shifted.mat', '20210505_ROI3_512_shifted.mat', '20210505_ROI4_512_shifted.mat', '20210526_ROI3_512_shifted.mat', '20210615_ROI1_512_shifted.mat', '20210622_ROI4_512_shifted.mat']\n",
            "20210420_ROI2_512_shifted\n",
            "20210420_ROI3_512_shifted\n",
            "20210421_ROI4_512_shifted\n",
            "20210421_ROI5_512_shifted\n",
            "20210426_ROI1_512_shifted\n",
            "20210426_ROI2_512_shifted\n",
            "20210426_ROI3_512_shifted\n",
            "20210426_ROI4_512_shifted\n",
            "20210505_ROI1_512_shifted\n",
            "20210505_ROI2_512_shifted\n",
            "20210505_ROI3_512_shifted\n",
            "20210505_ROI4_512_shifted\n",
            "20210526_ROI3_512_shifted\n",
            "20210615_ROI1_512_shifted\n",
            "20210622_ROI4_512_shifted\n",
            "count 362\n",
            "0\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "main_path = MAIN_PATH\n",
        "os.chdir(main_path+'/shifted_files')\n",
        "data_dict = {'40X':{'NADH':{}, 'FAD':{}, 'SHG':{}}, '25X':{'NADH':{}, 'FAD':{}, 'SHG':{}}}\n",
        "files = os.listdir()\n",
        "results_folders = []\n",
        "key_names = [] # to contain file names (ROIs) without '.mat'\n",
        "\n",
        "# constructing paths to paired_results folders\n",
        "# for file in files:\n",
        "#     new_path = os.path.join(main_path, file)\n",
        "#     if os.path.isdir(new_path) and 'results' in file:\n",
        "#         paired_path = os.path.join(new_path, 'paired_results')\n",
        "#         results_folders.append(paired_path)\n",
        "# Populating dictionary\n",
        "NADH = 0 # counting number of images\n",
        "FAD = 0\n",
        "# for result_folder in results_folders:\n",
        "roi_mats = [] # to contain full file names\n",
        "# os.chdir(result_folder)\n",
        "experiment_files = os.listdir()\n",
        "print(experiment_files)\n",
        "# appending .mat files with w40XShift to roi_mats\n",
        "for experiment_file in experiment_files:\n",
        "    if experiment_file.endswith('.mat') and '512_shifted' in experiment_file:\n",
        "        roi_mats.append(experiment_file)\n",
        "\n",
        "mean40x = []\n",
        "mean25x = []\n",
        "count = 0\n",
        "for roi in roi_mats:\n",
        "    roi_name = roi[0:-4]\n",
        "    print(roi_name)\n",
        "    key_names.append(roi_name)\n",
        "    mat_data = sio.loadmat(roi)\n",
        "    count = count + np.shape(mat_data['nadh_512_shifted'][:, :, :, 1])[2]\n",
        "    data_dict['40X']['NADH'][roi_name] = mat_data['nadh_512_shifted'][:, :, :, 1]\n",
        "    data_dict['25X']['NADH'][roi_name] = mat_data['nadh_512_shifted'][:, :, :, 0]\n",
        "del mat_data\n",
        "print(\"count\",count)\n",
        "\n",
        "WhereIWantToUseTheSound()\n",
        "print(NADH)\n",
        "print(FAD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtcB-DbhpqSS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7443c95f-3406-449d-b66c-4b0a64703748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stack shape:  (512, 512, 27) 20210420_ROI2_512_shifted\n",
            "SHAPE DATA:  (25, 512, 512, 3) 20210420_ROI2_512_shifted\n",
            "Stack shape:  (512, 512, 22) 20210420_ROI3_512_shifted\n",
            "SHAPE DATA:  (20, 512, 512, 3) 20210420_ROI3_512_shifted\n",
            "Stack shape:  (512, 512, 37) 20210421_ROI4_512_shifted\n",
            "SHAPE DATA:  (35, 512, 512, 3) 20210421_ROI4_512_shifted\n",
            "Stack shape:  (512, 512, 24) 20210421_ROI5_512_shifted\n",
            "SHAPE DATA:  (22, 512, 512, 3) 20210421_ROI5_512_shifted\n",
            "Stack shape:  (512, 512, 27) 20210426_ROI1_512_shifted\n",
            "SHAPE DATA:  (25, 512, 512, 3) 20210426_ROI1_512_shifted\n",
            "Stack shape:  (512, 512, 11) 20210426_ROI2_512_shifted\n",
            "SHAPE DATA:  (9, 512, 512, 3) 20210426_ROI2_512_shifted\n",
            "Stack shape:  (512, 512, 14) 20210426_ROI3_512_shifted\n",
            "SHAPE DATA:  (12, 512, 512, 3) 20210426_ROI3_512_shifted\n",
            "Stack shape:  (512, 512, 13) 20210426_ROI4_512_shifted\n",
            "SHAPE DATA:  (11, 512, 512, 3) 20210426_ROI4_512_shifted\n",
            "Stack shape:  (512, 512, 23) 20210505_ROI1_512_shifted\n",
            "SHAPE DATA:  (21, 512, 512, 3) 20210505_ROI1_512_shifted\n",
            "Stack shape:  (512, 512, 30) 20210505_ROI2_512_shifted\n",
            "SHAPE DATA:  (28, 512, 512, 3) 20210505_ROI2_512_shifted\n",
            "Stack shape:  (512, 512, 15) 20210505_ROI3_512_shifted\n",
            "SHAPE DATA:  (13, 512, 512, 3) 20210505_ROI3_512_shifted\n",
            "Stack shape:  (512, 512, 15) 20210505_ROI4_512_shifted\n",
            "SHAPE DATA:  (13, 512, 512, 3) 20210505_ROI4_512_shifted\n",
            "Stack shape:  (512, 512, 34) 20210526_ROI3_512_shifted\n",
            "SHAPE DATA:  (32, 512, 512, 3) 20210526_ROI3_512_shifted\n",
            "Stack shape:  (512, 512, 40) 20210615_ROI1_512_shifted\n",
            "SHAPE DATA:  (38, 512, 512, 3) 20210615_ROI1_512_shifted\n",
            "Stack shape:  (512, 512, 30) 20210622_ROI4_512_shifted\n",
            "SHAPE DATA:  (28, 512, 512, 3) 20210622_ROI4_512_shifted\n"
          ]
        }
      ],
      "source": [
        "# we are splitting train test val based on stacks, we have a total of 15 stacks\n",
        "# we are generating 3D patches with each patch is 3D over set of depths of interest\n",
        "training_indices = [0, 2, 4, 5, 6, 8, 9,10,11,12,7,13,14]\n",
        "training_keys = [key_names[i] for i in training_indices]\n",
        "val_indices = [1, 3, 6]\n",
        "val_keys = [key_names[i] for i in val_indices]\n",
        "# test_indices = [12, 13]\n",
        "# test_keys = [key_names[i] for i in test_indices]\n",
        "\n",
        "training_data = []\n",
        "training_data_labels = []\n",
        "# test_data = []\n",
        "# test_data_labels = []\n",
        "val_data = []\n",
        "val_data_labels =[]\n",
        "# max_depth = 10 # only taking total of 11 depths for consistency\n",
        "\n",
        "\n",
        "for key in key_names:\n",
        "    [data, label] = preprocess3D_fullsize_3_depths(data_dict, key, types='NADH', process=\"up\")\n",
        "    if key in training_keys:\n",
        "        training_data = concatenate(training_data,data)\n",
        "        training_data_labels = concatenate(training_data_labels,label)\n",
        "    elif key in val_keys:\n",
        "        val_data = concatenate(val_data,data)\n",
        "        val_data_labels = concatenate(val_data_labels,label)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(training_data),np.shape(training_data_labels),np.shape(val_data),np.shape(val_data_labels))\n",
        "# np.set_printoptions(threshold=np.inf)\n",
        "# mean40x = np.amax(training_data,axis=(1,2))\n",
        "# plt.figure(figsize=(10,10))\n",
        "# plt.hist(mean40x,bins=np.unique(mean40x))\n",
        "# value, count = np.unique(mean40x, return_counts=True)\n",
        "# print(value)\n",
        "# print(count)\n",
        "\n",
        "# mean25x = np.amax(training_data_labels,axis=(1,2))\n",
        "# plt.figure(figsize=(10,10))\n",
        "# plt.hist(mean25x,bins=np.unique(mean25x))\n",
        "# print(np.shape(mean25x))\n",
        "# value, count = np.unique(mean25x, return_counts=True)\n",
        "# print(value)\n",
        "# print(count)"
      ],
      "metadata": {
        "id": "UAeDaCc0WeSf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2e6d17b-9b64-43a5-8f52-520c5aa98d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(290, 512, 512, 3) (290, 512, 512, 3) (42, 512, 512, 3) (42, 512, 512, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ye8wTwjHSRa"
      },
      "outputs": [],
      "source": [
        "# # split 1024x1024px images into test and train/val and save all images with mixed depths into corresponding list in dict\n",
        "# test_dict = {'40X':{'NADH':[], 'FAD':[], 'SHG':[]}, '25X':{'NADH':[], 'FAD':[], 'SHG':[]}}\n",
        "# for key in TYPES:\n",
        "#   ids = range(len(data_dict['25X'][key]))\n",
        "#   X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(ids, ids, test_size=TEST_SIZE, random_state=1,shuffle=True)\n",
        "#   test_dict['25X'][key] = concatenate(test_dict['25X'][key],data_dict['25X'][key][X_test, :,:])\n",
        "#   test_dict['40X'][key] = concatenate(test_dict['40X'][key],data_dict['40X'][key][X_test, :,:])\n",
        "#   data_dict['25X'][key] = np.delete(data_dict['25X'][key], X_test,axis=0)\n",
        "#   data_dict['40X'][key] = np.delete(data_dict['40X'][key], X_test,axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# avoid having the same stack appear in both training and testing"
      ],
      "metadata": {
        "id": "PFqef0Fy_HPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWFOvgwGVqXf"
      },
      "outputs": [],
      "source": [
        "# # preprocessing and patching data\n",
        "# # plt.figure(figsize = (10,10))\n",
        "# # plt.imshow(data_dict['40X']['NADH'][25,:,:])\n",
        "# [data, labels] = preprocess(data_dict, PATCH_SIZE, OVERLAP, types=['NADH'], process=\"up\")\n",
        "# # del data_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-ViEWSNRqKy"
      },
      "outputs": [],
      "source": [
        "# # preprocessing and patching test data\n",
        "# [test_data, test_data_labels] = preprocess(test_dict, PATCH_SIZE, OVERLAP, types=['NADH'], process=\"up\")\n",
        "# # del test_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjyW5lSEu-JE"
      },
      "outputs": [],
      "source": [
        "# # splitting train and validation\n",
        "# # bloddy hell the train_test_split blows up memory, instead splitting ids\n",
        "# ids = range(data.shape[0])\n",
        "# X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(ids, ids, test_size=VAL_SIZE/(1-TEST_SIZE), random_state=1,shuffle=True)\n",
        "\n",
        "# training_data = data[X_train,:,:]\n",
        "# data[X_train,:,:] = 0\n",
        "# val_data = data[X_val,:,:]\n",
        "# data[X_val,:,:] = 0\n",
        "# del data\n",
        "# training_data_labels = labels[y_train,:,:]\n",
        "# labels[y_train,:,:] = 0\n",
        "# val_data_labels = labels[y_val,:,:]\n",
        "# labels[y_val,:,:] = 0\n",
        "# del labels\n",
        "# print(\"Train size, test size, and validation size: \",training_data.shape,\", \",val_data.shape)\n",
        "# WhereIWantToUseTheSound()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"training\", np.shape(training_data))\n",
        "print(\"val\",np.shape(val_data))\n",
        "print(np.unique(training_data[0,...]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fHUt8928sWg",
        "outputId": "e9ef38ec-271b-4437-8516-5a3d5afd8429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training (290, 512, 512, 3)\n",
            "val (42, 512, 512, 3)\n",
            "[0.         0.03293577 0.03369485 ... 1.32610298 1.33410551 1.33887734]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.hist(training_data[0,...,0].flatten(), bins=120)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.hist(training_data_labels[0,...,0].flatten(), bins=120)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y3ZTJzTP8yNr",
        "outputId": "9c3bdb21-2799-463b-8680-872eb731e7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([7.9280e+03, 0.0000e+00, 1.5250e+03, 0.0000e+00, 0.0000e+00,\n",
              "        4.5720e+03, 0.0000e+00, 2.1000e+01, 9.1530e+03, 0.0000e+00,\n",
              "        1.2900e+02, 1.4795e+04, 0.0000e+00, 3.5500e+02, 1.9815e+04,\n",
              "        8.1100e+02, 2.8000e+01, 2.3621e+04, 1.4050e+03, 4.4000e+01,\n",
              "        2.4564e+04, 2.2000e+03, 2.3850e+04, 4.8000e+01, 2.7760e+03,\n",
              "        2.1423e+04, 1.1100e+02, 3.4520e+03, 1.8019e+04, 7.0000e+00,\n",
              "        3.6740e+03, 1.4562e+04, 8.0000e+00, 3.7240e+03, 1.1408e+04,\n",
              "        3.5470e+03, 3.7000e+01, 8.5730e+03, 3.1860e+03, 3.5000e+01,\n",
              "        6.2260e+03, 2.7570e+03, 3.8680e+03, 5.6700e+02, 2.2640e+03,\n",
              "        2.5840e+03, 5.4900e+02, 1.8660e+03, 1.5960e+03, 5.2300e+02,\n",
              "        1.3940e+03, 1.5130e+03, 5.0000e+00, 1.0990e+03, 1.0340e+03,\n",
              "        7.1600e+02, 1.0600e+02, 7.2900e+02, 4.6400e+02, 8.1000e+01,\n",
              "        4.8000e+02, 2.9400e+02, 2.0100e+02, 2.6000e+02, 2.8600e+02,\n",
              "        7.0000e+01, 1.4300e+02, 1.6700e+02, 3.9000e+01, 1.4000e+02,\n",
              "        1.2000e+02, 9.0000e+01, 2.2000e+01, 9.3000e+01, 4.8000e+01,\n",
              "        2.1000e+01, 6.6000e+01, 5.4000e+01, 8.0000e+00, 2.4000e+01,\n",
              "        3.7000e+01, 6.0000e+00, 1.8000e+01, 2.0000e+01, 1.4000e+01,\n",
              "        8.0000e+00, 9.0000e+00, 4.0000e+00, 5.0000e+00, 8.0000e+00,\n",
              "        5.0000e+00, 6.0000e+00, 5.0000e+00, 1.0000e+00, 1.0000e+00,\n",
              "        5.0000e+00, 2.0000e+00, 2.0000e+00, 1.0000e+00, 3.0000e+00,\n",
              "        1.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 1.0000e+00,\n",
              "        0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
              " array([0.        , 0.01304325, 0.0260865 , 0.03912975, 0.052173  ,\n",
              "        0.06521625, 0.07825951, 0.09130276, 0.10434601, 0.11738926,\n",
              "        0.13043251, 0.14347576, 0.15651901, 0.16956226, 0.18260551,\n",
              "        0.19564876, 0.20869202, 0.22173527, 0.23477852, 0.24782177,\n",
              "        0.26086502, 0.27390827, 0.28695152, 0.29999477, 0.31303802,\n",
              "        0.32608127, 0.33912453, 0.35216778, 0.36521103, 0.37825428,\n",
              "        0.39129753, 0.40434078, 0.41738403, 0.43042728, 0.44347053,\n",
              "        0.45651378, 0.46955703, 0.48260029, 0.49564354, 0.50868679,\n",
              "        0.52173004, 0.53477329, 0.54781654, 0.56085979, 0.57390304,\n",
              "        0.58694629, 0.59998954, 0.6130328 , 0.62607605, 0.6391193 ,\n",
              "        0.65216255, 0.6652058 , 0.67824905, 0.6912923 , 0.70433555,\n",
              "        0.7173788 , 0.73042205, 0.74346531, 0.75650856, 0.76955181,\n",
              "        0.78259506, 0.79563831, 0.80868156, 0.82172481, 0.83476806,\n",
              "        0.84781131, 0.86085456, 0.87389781, 0.88694107, 0.89998432,\n",
              "        0.91302757, 0.92607082, 0.93911407, 0.95215732, 0.96520057,\n",
              "        0.97824382, 0.99128707, 1.00433032, 1.01737358, 1.03041683,\n",
              "        1.04346008, 1.05650333, 1.06954658, 1.08258983, 1.09563308,\n",
              "        1.10867633, 1.12171958, 1.13476283, 1.14780608, 1.16084934,\n",
              "        1.17389259, 1.18693584, 1.19997909, 1.21302234, 1.22606559,\n",
              "        1.23910884, 1.25215209, 1.26519534, 1.27823859, 1.29128185,\n",
              "        1.3043251 , 1.31736835, 1.3304116 , 1.34345485, 1.3564981 ,\n",
              "        1.36954135, 1.3825846 , 1.39562785, 1.4086711 , 1.42171436,\n",
              "        1.43475761, 1.44780086, 1.46084411, 1.47388736, 1.48693061,\n",
              "        1.49997386, 1.51301711, 1.52606036, 1.53910361, 1.55214686,\n",
              "        1.56519012]),\n",
              " <a list of 120 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.count_nonzero((training_data_labels)<0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUSaVvxWmP0H",
        "outputId": "4e4effe7-acdd-4d9c-c5c9-b35d746ad0be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "773904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFRpE9D-l38I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c2b3ad2-d5d9-440b-ee60-5d64240914c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(290, 512, 512, 3)\n"
          ]
        }
      ],
      "source": [
        "print(np.shape(training_data))\n",
        "np.savez(MAIN_PATH+'/deep_learning/npz/Cervix_all_data'+str(NPZ_VER)+'.npz',t= np.float32(training_data), v=np.float32(val_data))\n",
        "np.savez(MAIN_PATH+'/deep_learning/npz/Cervix_all_data_labels'+ str(NPZ_VER)+'.npz',t= np.float32(training_data_labels), v=np.float32(val_data_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FqKkqfTGL48w"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "gpu2",
      "language": "python",
      "name": "gpu2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
