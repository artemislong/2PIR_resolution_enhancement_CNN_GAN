{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9cg_oeV3lch",
        "outputId": "90a97031-55ea-438e-c949-d598c7931134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 31.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OppoldwU3HN3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import skimage\n",
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import keras.backend as K\n",
        "from datetime import datetime\n",
        "import fractions\n",
        "import itertools\n",
        "import tqdm\n",
        "from keras.utils.conv_utils import normalize_tuple\n",
        "import os\n",
        "import scipy\n",
        "from datetime import datetime\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "import scipy.io\n",
        "\n",
        "now = datetime.now() # current date and time\n",
        "CURR_DATE = now.strftime(\"%m-%d-%Y\")\n",
        "MODEL_NAME = \"CARE\"+CURR_DATE\n",
        "\n",
        "DATA_PATH = '/npz/Cervix_all_data_original.npz'\n",
        "LABEL_PATH = '/npz/Cervix_all_data_labels_original.npz'\n",
        "MODEL_PATH = '/CAREstd/checkpoint/weights.132-1.20_n1t1d3.hdf5'\n",
        "MAIN_PATH= r\"/objective_transfer/deep_learning\" # Artem's Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sw5a6kzk3SRP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Weights initializer for the layers.\n",
        "kernel_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "# Gamma initializer for instance normalization.\n",
        "gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "PATCH_SIZE = 512\n",
        "input_img_size = (PATCH_SIZE, PATCH_SIZE,1)\n",
        "\n",
        "\n",
        "# cycleGAN\n",
        "\"\"\"\n",
        "## Building blocks used in the CycleGAN generators and discriminators\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class ReflectionPadding2D(layers.Layer):\n",
        "    \"\"\"Implements Reflection Padding as a layer.\n",
        "    Args:\n",
        "        padding(tuple): Amount of padding for the\n",
        "        spatial dimensions.\n",
        "    Returns:\n",
        "        A padded tensor with the same type as the input tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, padding=(1, 1), **kwargs):\n",
        "        self.padding = tuple(padding)\n",
        "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, input_tensor, mask=None):\n",
        "        padding_width, padding_height = self.padding\n",
        "        padding_tensor = [\n",
        "            [0, 0],\n",
        "            [padding_height, padding_height],\n",
        "            [padding_width, padding_width],\n",
        "            [0, 0],\n",
        "        ]\n",
        "        return tf.pad(input_tensor, padding_tensor, mode=\"REFLECT\")\n",
        "\n",
        "\n",
        "def residual_block(\n",
        "    x,\n",
        "    activation,\n",
        "    kernel_initializer=kernel_init,\n",
        "    kernel_size=(3, 3),\n",
        "    strides=(1, 1),\n",
        "    padding=\"valid\",\n",
        "    gamma_initializer=gamma_init,\n",
        "    use_bias=False,\n",
        "):\n",
        "    dim = x.shape[-1]\n",
        "    input_tensor = x\n",
        "\n",
        "    x = ReflectionPadding2D()(input_tensor)\n",
        "    x = layers.Conv2D(\n",
        "        dim,\n",
        "        kernel_size,\n",
        "        strides=strides,\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        padding=padding,\n",
        "        use_bias=use_bias,\n",
        "    )(x)\n",
        "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
        "    x = activation(x)\n",
        "\n",
        "    x = ReflectionPadding2D()(x)\n",
        "    x = layers.Conv2D(\n",
        "        dim,\n",
        "        kernel_size,\n",
        "        strides=strides,\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        padding=padding,\n",
        "        use_bias=use_bias,\n",
        "    )(x)\n",
        "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
        "    x = layers.add([input_tensor, x])\n",
        "    return x\n",
        "\n",
        "\n",
        "def downsample(\n",
        "    x,\n",
        "    filters,\n",
        "    activation,\n",
        "    kernel_initializer=kernel_init,\n",
        "    kernel_size=(3, 3),\n",
        "    strides=(2, 2),\n",
        "    padding=\"same\",\n",
        "    gamma_initializer=gamma_init,\n",
        "    use_bias=False,\n",
        "):\n",
        "    x = layers.Conv2D(\n",
        "        filters,\n",
        "        kernel_size,\n",
        "        strides=strides,\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        padding=padding,\n",
        "        use_bias=use_bias,\n",
        "    )(x)\n",
        "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
        "    if activation:\n",
        "        x = activation(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def upsample(\n",
        "    x,\n",
        "    filters,\n",
        "    activation,\n",
        "    kernel_size=(3, 3),\n",
        "    strides=(2, 2),\n",
        "    padding=\"same\",\n",
        "    kernel_initializer=kernel_init,\n",
        "    gamma_initializer=gamma_init,\n",
        "    use_bias=False,\n",
        "):\n",
        "    x = layers.Conv2DTranspose(\n",
        "        filters,\n",
        "        kernel_size,\n",
        "        strides=strides,\n",
        "        padding=padding,\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        use_bias=use_bias,\n",
        "    )(x)\n",
        "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
        "    if activation:\n",
        "        x = activation(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "## Build the generators\n",
        "The generator consists of downsampling blocks: nine residual blocks\n",
        "and upsampling blocks. The structure of the generator is the following:\n",
        "```\n",
        "c7s1-64 ==> Conv block with `relu` activation, filter size of 7\n",
        "d128 ====|\n",
        "         |-> 2 downsampling blocks\n",
        "d256 ====|\n",
        "R256 ====|\n",
        "R256     |\n",
        "R256     |\n",
        "R256     |\n",
        "R256     |-> 9 residual blocks\n",
        "R256     |\n",
        "R256     |\n",
        "R256     |\n",
        "R256 ====|\n",
        "u128 ====|\n",
        "         |-> 2 upsampling blocks\n",
        "u64  ====|\n",
        "c7s1-3 => Last conv block with `tanh` activation, filter size of 7.\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def get_resnet_generator(\n",
        "    filters=64,\n",
        "    num_downsampling_blocks=2,\n",
        "    num_residual_blocks=9,\n",
        "    num_upsample_blocks=2,\n",
        "    gamma_initializer=gamma_init,\n",
        "    name=None,\n",
        "):\n",
        "    img_input = layers.Input(shape=input_img_size, name=name + \"_img_input\")\n",
        "    x = ReflectionPadding2D(padding=(3, 3))(img_input)\n",
        "    x = layers.Conv2D(filters, (7, 7), kernel_initializer=kernel_init, use_bias=False)(x)\n",
        "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    # Downsampling\n",
        "    for _ in range(num_downsampling_blocks):\n",
        "        filters *= 2\n",
        "        x = downsample(x, filters=filters, activation=layers.Activation(\"relu\"))\n",
        "\n",
        "    # Residual blocks\n",
        "    for _ in range(num_residual_blocks):\n",
        "        x = residual_block(x, activation=layers.Activation(\"relu\"))\n",
        "\n",
        "    # Upsampling\n",
        "    for _ in range(num_upsample_blocks):\n",
        "        filters //= 2\n",
        "        x = upsample(x, filters, activation=layers.Activation(\"relu\"))\n",
        "\n",
        "    # Final block\n",
        "    x = ReflectionPadding2D(padding=(3, 3))(x)\n",
        "    x = layers.Conv2D(1, (7, 7), padding=\"valid\")(x)\n",
        "    x = layers.Activation(\"tanh\")(x)\n",
        "\n",
        "    model = keras.models.Model(img_input, x, name=name)\n",
        "    return model\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "## Build the discriminators\n",
        "The discriminators implement the following architecture:\n",
        "`C64->C128->C256->C512`\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def get_discriminator(\n",
        "    filters=64, kernel_initializer=kernel_init, num_downsampling=3, name=None\n",
        "):\n",
        "    img_input = layers.Input(shape=input_img_size, name=name + \"_img_input\")\n",
        "    x = layers.Conv2D(\n",
        "        filters,\n",
        "        (4, 4),\n",
        "        strides=(2, 2),\n",
        "        padding=\"same\",\n",
        "        kernel_initializer=kernel_initializer,\n",
        "    )(img_input)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    num_filters = filters\n",
        "    for num_downsample_block in range(3):\n",
        "        num_filters *= 2\n",
        "        if num_downsample_block < 2:\n",
        "            x = downsample(\n",
        "                x,\n",
        "                filters=num_filters,\n",
        "                activation=layers.LeakyReLU(0.2),\n",
        "                kernel_size=(4, 4),\n",
        "                strides=(2, 2),\n",
        "            )\n",
        "        else:\n",
        "            x = downsample(\n",
        "                x,\n",
        "                filters=num_filters,\n",
        "                activation=layers.LeakyReLU(0.2),\n",
        "                kernel_size=(4, 4),\n",
        "                strides=(1, 1),\n",
        "            )\n",
        "\n",
        "    x = layers.Conv2D(\n",
        "        1, (4, 4), strides=(1, 1), padding=\"same\", kernel_initializer=kernel_initializer\n",
        "    )(x)\n",
        "\n",
        "    model = keras.models.Model(inputs=img_input, outputs=x, name=name)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Get the generators\n",
        "gen_G = get_resnet_generator(name=\"generator_G\")\n",
        "gen_F = get_resnet_generator(name=\"generator_F\")\n",
        "\n",
        "# Get the discriminators\n",
        "disc_X = get_discriminator(name=\"discriminator_X\")\n",
        "disc_Y = get_discriminator(name=\"discriminator_Y\")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "## Build the CycleGAN model\n",
        "We will override the `train_step()` method of the `Model` class\n",
        "for training via `fit()`.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class CycleGan(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        generator_G,\n",
        "        generator_F,\n",
        "        discriminator_X,\n",
        "        discriminator_Y,\n",
        "        lambda_cycle=10.0,\n",
        "        lambda_identity=0.5,\n",
        "    ):\n",
        "        super(CycleGan, self).__init__()\n",
        "        self.gen_G = generator_G\n",
        "        self.gen_F = generator_F\n",
        "        self.disc_X = discriminator_X\n",
        "        self.disc_Y = discriminator_Y\n",
        "        self.lambda_cycle = lambda_cycle\n",
        "        self.lambda_identity = lambda_identity\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return (\n",
        "            self.disc_X(inputs),\n",
        "            self.disc_Y(inputs),\n",
        "            self.gen_G(inputs),\n",
        "            self.gen_F(inputs),\n",
        "        )\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        gen_G_optimizer,\n",
        "        gen_F_optimizer,\n",
        "        disc_X_optimizer,\n",
        "        disc_Y_optimizer,\n",
        "        gen_loss_fn,\n",
        "        disc_loss_fn,\n",
        "        metrics\n",
        "    ):\n",
        "        super(CycleGan, self).compile(metrics=metrics)\n",
        "        self.gen_G_optimizer = gen_G_optimizer\n",
        "        self.gen_F_optimizer = gen_F_optimizer\n",
        "        self.disc_X_optimizer = disc_X_optimizer\n",
        "        self.disc_Y_optimizer = disc_Y_optimizer\n",
        "        self.generator_loss_fn = gen_loss_fn\n",
        "        self.discriminator_loss_fn = disc_loss_fn\n",
        "        self.cycle_loss_fn = keras.losses.MeanAbsoluteError()\n",
        "        self.identity_loss_fn = keras.losses.MeanAbsoluteError() # TODO: disable\n",
        "\n",
        "    def train_step(self, batch_data):\n",
        "        # x is Horse and y is zebra\n",
        "        # print(\"BATCH DATA: \", batch_data)\n",
        "        real_x, real_y = batch_data\n",
        "\n",
        "        # For CycleGAN, we need to calculate different\n",
        "        # kinds of losses for the generators and discriminators.\n",
        "        # We will perform the following steps here:\n",
        "        #\n",
        "        # 1. Pass real images through the generators and get the generated images\n",
        "        # 2. Pass the generated images back to the generators to check if we\n",
        "        #    we can predict the original image from the generated image.\n",
        "        # 3. Do an identity mapping of the real images using the generators.\n",
        "        # 4. Pass the generated images in 1) to the corresponding discriminators.\n",
        "        # 5. Calculate the generators total loss (adverserial + cycle + identity)\n",
        "        # 6. Calculate the discriminators loss\n",
        "        # 7. Update the weights of the generators\n",
        "        # 8. Update the weights of the discriminators\n",
        "        # 9. Return the losses in a dictionary\n",
        "\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            # print(\"1\")\n",
        "            # Horse to fake zebra\n",
        "            fake_y = self.gen_G(real_x, training=True)\n",
        "            # Zebra to fake horse -> y2x\n",
        "            fake_x = self.gen_F(real_y, training=True)\n",
        "            # Cycle (Horse to fake zebra to fake horse): x -> y -> x\n",
        "            cycled_x = self.gen_F(fake_y, training=True)\n",
        "            # Cycle (Zebra to fake horse to fake zebra) y -> x -> y\n",
        "            cycled_y = self.gen_G(fake_x, training=True)\n",
        "            # Identity mapping\n",
        "            same_x = self.gen_F(real_x, training=True)\n",
        "            same_y = self.gen_G(real_y, training=True)\n",
        "            # print(\"4\")\n",
        "            # Discriminator output\n",
        "            disc_real_x = self.disc_X(real_x, training=True)\n",
        "            disc_fake_x = self.disc_X(fake_x, training=True)\n",
        "\n",
        "            disc_real_y = self.disc_Y(real_y, training=True)\n",
        "            disc_fake_y = self.disc_Y(fake_y, training=True)\n",
        "            # print(\"5\")\n",
        "            # Generator adverserial loss\n",
        "            gen_G_loss = self.generator_loss_fn(disc_fake_y)\n",
        "            gen_F_loss = self.generator_loss_fn(disc_fake_x)\n",
        "            # print(\"6\")\n",
        "            # Generator cycle loss\n",
        "            cycle_loss_G = self.cycle_loss_fn(real_y, cycled_y) * self.lambda_cycle\n",
        "            cycle_loss_F = self.cycle_loss_fn(real_x, cycled_x) * self.lambda_cycle\n",
        "            # print(\"7\")\n",
        "            # Generator identity loss\n",
        "            id_loss_G = (\n",
        "                self.identity_loss_fn(real_y, same_y)\n",
        "                * self.lambda_cycle\n",
        "                * self.lambda_identity\n",
        "            )\n",
        "            id_loss_F = (\n",
        "                self.identity_loss_fn(real_x, same_x)\n",
        "                * self.lambda_cycle\n",
        "                * self.lambda_identity\n",
        "            )\n",
        "            # print(\"8\")\n",
        "            # Total generator loss\n",
        "            total_loss_G = gen_G_loss + cycle_loss_G + id_loss_G\n",
        "            total_loss_F = gen_F_loss + cycle_loss_F + id_loss_F\n",
        "            # print(\"9\")\n",
        "            # Discriminator loss\n",
        "            disc_X_loss = self.discriminator_loss_fn(disc_real_x, disc_fake_x)\n",
        "            disc_Y_loss = self.discriminator_loss_fn(disc_real_y, disc_fake_y)\n",
        "\n",
        "        # Get the gradients for the generators\n",
        "        grads_G = tape.gradient(total_loss_G, self.gen_G.trainable_variables)\n",
        "        grads_F = tape.gradient(total_loss_F, self.gen_F.trainable_variables)\n",
        "        # print(\"10\")\n",
        "        # Get the gradients for the discriminators\n",
        "        disc_X_grads = tape.gradient(disc_X_loss, self.disc_X.trainable_variables)\n",
        "        disc_Y_grads = tape.gradient(disc_Y_loss, self.disc_Y.trainable_variables)\n",
        "        # print(\"11\")\n",
        "        # Update the weights of the generators\n",
        "        self.gen_G_optimizer.apply_gradients(\n",
        "            zip(grads_G, self.gen_G.trainable_variables)\n",
        "        )\n",
        "        self.gen_F_optimizer.apply_gradients(\n",
        "            zip(grads_F, self.gen_F.trainable_variables)\n",
        "        )\n",
        "        # print(\"12\")\n",
        "        # Update the weights of the discriminators\n",
        "        self.disc_X_optimizer.apply_gradients(\n",
        "            zip(disc_X_grads, self.disc_X.trainable_variables)\n",
        "        )\n",
        "        self.disc_Y_optimizer.apply_gradients(\n",
        "            zip(disc_Y_grads, self.disc_Y.trainable_variables)\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"G_loss\": total_loss_G,\n",
        "            \"F_loss\": total_loss_F,\n",
        "            \"D_X_loss\": disc_X_loss,\n",
        "            \"D_Y_loss\": disc_Y_loss,\n",
        "        }\n",
        "\n",
        "# Loss function for evaluating adversarial loss\n",
        "adv_loss_fn = keras.losses.MeanSquaredError()\n",
        "\n",
        "def generator_loss_fn(fake):\n",
        "  fake_loss = adv_loss_fn(tf.ones_like(fake), fake)\n",
        "  return fake_loss\n",
        "\n",
        "\n",
        "# Define the loss function for the discriminators\n",
        "def discriminator_loss_fn(real, fake):\n",
        "    real_loss = adv_loss_fn(tf.ones_like(real), real)\n",
        "    fake_loss = adv_loss_fn(tf.zeros_like(fake), fake)\n",
        "    return (real_loss + fake_loss) * 0.5"
      ],
      "metadata": {
        "id": "4-puuXKmcWHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeJlUngX38Jk"
      },
      "outputs": [],
      "source": [
        "def expandLastDim(data):\n",
        "    return np.expand_dims(data, -1)\n",
        "\n",
        "def normalizen1to1(img):\n",
        "  # Normalizing images between 0 and 1 and preserving distribution\n",
        "  img_norm = 2*(img - np.amin(img))/( np.amax(img)- np.amin(img)) - 1\n",
        "  return img_norm\n",
        "\n",
        "def load_data(path, expand=False, normalize=False):\n",
        "    # Loading preprocessed image patches and adding 4th arbitrary dimension\n",
        "    b = np.load(path)\n",
        "    training_data = b['t']\n",
        "    val_data = b['v']\n",
        "    if expand == True:\n",
        "      training_data = expandLastDim(training_data)\n",
        "      val_data = expandLastDim(val_data)\n",
        "    if normalize:\n",
        "      training_data = [normalize0to1(m) for m in training_data]\n",
        "      val_data = [normalize0to1(m) for m in val_data]\n",
        "    return [training_data, val_data ]\n",
        "\n",
        "def create_patches(img, patch_shape, slide):\n",
        "    # returns stack of patches and number of patches\n",
        "    patch_img = skimage.util.view_as_windows(img, (patch_shape,patch_shape), step=patch_shape-slide)\n",
        "    patch = patch_img.reshape(patch_img.shape[0]*patch_img.shape[1],patch_shape,patch_shape) # more time efficient\n",
        "    return patch\n",
        "\n",
        "def patchify(input, patch_shape, slide):\n",
        "    # getting number of input images\n",
        "    len_to_allocate = int(np.shape(input)[0]*((slide-np.shape(input)[1]) / (slide-patch_shape))**2)\n",
        "    data = np.zeros((len_to_allocate,patch_shape,patch_shape))\n",
        "    count = 0\n",
        "    # print(\"preparing to patchify: input, patch shape, slide\",np.shape(input), patch_shape, slide)\n",
        "    for i in range(np.shape(input)[0]):\n",
        "      A = create_patches(input[i], patch_shape, slide)\n",
        "      data[count:count+len(A),:,:] = A[:,:,:]\n",
        "      count = count + len(A)\n",
        "    print(\"      [PATCHIFYING COMPLETED] output shape, slide: \",np.shape(data),slide,\"; number of images: \", np.shape(input)[0], \", number of patches: \", np.shape(data)[0])\n",
        "    return data\n",
        "\n",
        "def psnr(y_true, y_pred):\n",
        "    '''\n",
        "    Computs the peak signal-to-noise ratio between two images. Note that the\n",
        "    maximum signal value is assumed to be 1.\n",
        "    '''\n",
        "    return tf.image.psnr(y_true, y_pred, max_val=1.0)\n",
        "\n",
        "def ssim(y_true, y_pred):\n",
        "    return tf.image.ssim(y_true, y_pred, 1, filter_size=3, filter_sigma=0.5, k2=0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSCcX1nv6cId"
      },
      "outputs": [],
      "source": [
        "def normalize0to1(img):\n",
        "  # Normalizing images between 0 and 1 and preserving distribution\n",
        "  if np.amin(img) == np.amax(img):\n",
        "    print(\"ERROR, MAX AND MIN ARE EQUAL\")\n",
        "    return np.zeros_like(img)\n",
        "  img_norm = (img - np.amin(img))/( np.amax(img)- np.amin(img))\n",
        "  return img_norm\n",
        "\n",
        "def mse(img1, img2):\n",
        "  m = tf.keras.metrics.MeanSquaredError()\n",
        "  m.update_state(img1, img2)\n",
        "  return m.result().numpy()\n",
        "\n",
        "def plot(img, label, hist=False, size=(10,10)):\n",
        "  plt.figure(figsize = size)\n",
        "  plt.axis('off')\n",
        "  if hist==True:\n",
        "    plt.hist(img.flatten(), bins=120)\n",
        "    plt.axis('on')\n",
        "  else: plt.imshow(img,cmap=\"gray\")\n",
        "  plt.title(label)\n",
        "\n",
        "def plotThree(allThree, title, hist=False, save=False, savePath = None):\n",
        "  # plot and saving merged images\n",
        "  _, ax = plt.subplots(1, 3, figsize=(30,10))\n",
        "  if hist:\n",
        "    if np.shape(allThree[0])[0] > 1:\n",
        "      raw = allThree[0].flatten()\n",
        "      pred = allThree[1].flatten()\n",
        "      gt = allThree[2].flatten()\n",
        "    else:\n",
        "      raw = allThree[0]\n",
        "      pred = allThree[1]\n",
        "      gt = allThree[2]\n",
        "    print('raw | mean, median: ',np.mean(raw), np.median(raw))\n",
        "    print('pred | mean, median: ',np.mean(pred), np.median(pred))\n",
        "    print('gt | mean, median: ',np.mean(gt), np.median(gt))\n",
        "    ax[0].hist(raw, bins=100)\n",
        "    ax[1].hist(pred, bins=100)\n",
        "    ax[2].hist(gt, bins=100)\n",
        "  else:\n",
        "    ax[0].imshow(allThree[0])\n",
        "    ax[1].imshow(allThree[1])\n",
        "    ax[2].imshow(allThree[2])\n",
        "  ax[0].set_title(\"Input image\")\n",
        "  ax[1].set_title(\"Translated image\")\n",
        "  ax[2].set_title(\"GT image\")\n",
        "  # ax[0].axis(\"off\")\n",
        "  # ax[1].axis(\"off\")\n",
        "  # ax[2].axis(\"off\")\n",
        "  plt.show()\n",
        "\n",
        "def getMode(x):\n",
        "    values, counts = np.unique(x, return_counts=True)\n",
        "    m = counts.argmax()\n",
        "    # print(\"mode\", m)\n",
        "    return values[m]\n",
        "\n",
        "def revert_img(img,original_size, patch_shape, slide):\n",
        "  # reverts original image and removes overlaps by splitting overlap over 2 images\n",
        "  step = int(patch_shape-slide)\n",
        "  reconstructed_arr = np.zeros((original_size,original_size))\n",
        "  for x in range(img.shape[0]):\n",
        "    for y in range(img.shape[1]):\n",
        "      start_x = int(slide/2)\n",
        "      start_y = int(slide/2)\n",
        "      end_x = 0\n",
        "      end_y = 0\n",
        "      if x == 0:\n",
        "        start_x = 0\n",
        "        end_x = int(slide/2)\n",
        "      if y == 0:\n",
        "        start_y = 0\n",
        "        end_y = int(slide/2)\n",
        "      if x == img.shape[0]-1: end_x = int(slide/2)\n",
        "      if y == img.shape[1]-1: end_y = int(slide/2)\n",
        "      x_pos, y_pos = x * step + start_x, y * step + start_y\n",
        "      # print('x_pos, start_x: ',x_pos, start_x)\n",
        "      # print('x_pos + step + end_x, start_x+step+end_x: ',x_pos + step + end_x, start_x+step+end_x)\n",
        "      # print('y_pos, start_y: ',y_pos, start_y)\n",
        "      # print('y_pos + step + end_y,  start_y+step+end_y: ',y_pos + step + end_y,  start_y+step+end_y)\n",
        "      # print(\"end===============x,y: \",x,y)\n",
        "      reconstructed_arr[x_pos : x_pos + step + end_x, y_pos : y_pos + step + end_y] = img[x, y, start_x:start_x+step+end_x, start_y:start_y+step+end_y]\n",
        "  return reconstructed_arr\n",
        "\n",
        "def merge_patches(img, original_size, patch_shape, slide):\n",
        "  #  merging patches, img is a 3D array of stacked patches\n",
        "  print(\"merging patches, img shape: \", img.shape, )\n",
        "  row_len = int(math.sqrt(img.shape[0]))\n",
        "  patches = np.zeros((row_len,row_len,patch_shape,patch_shape))\n",
        "  print(img.shape)\n",
        "  print(patches.shape)\n",
        "  for r in range(row_len):\n",
        "      patches[r,:,:,:] = img[r*row_len:r*row_len+row_len,:,:]\n",
        "  # plt.figure(5)\n",
        "  # plt.imshow(patches[1,1,:,:])\n",
        "  return revert_img(patches,original_size,patch_shape, slide)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OHmkoVh3vcF"
      },
      "outputs": [],
      "source": [
        "# loading data\n",
        "[training_data, val_data] = load_data(MAIN_PATH+DATA_PATH, expand=False, normalize=True) # change normalize property, CARE = false, CycleGAN = true\n",
        "[training_data_labels,val_data_labels] = load_data(MAIN_PATH+LABEL_PATH, expand=False, normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWkgIwqQ6Zbp"
      },
      "outputs": [],
      "source": [
        "# predicting\n",
        "data_set = \"val\" # change this\n",
        "patch = 128\n",
        "slide = 64\n",
        "if data_set == \"train\":\n",
        "  input = training_data\n",
        "  ground_truth = training_data_labels\n",
        "else:\n",
        "  input = val_data\n",
        "  ground_truth = val_data_labels\n",
        "if patch < 512:\n",
        "    pretrain = patchify(input, patch, slide)\n",
        "else: pretrain = input\n",
        "pretrain, input, ground_truth = [expandLastDim(m) for m in [pretrain, input, ground_truth]]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"input\",np.shape(pretrain))"
      ],
      "metadata": {
        "id": "by0FkpzPgHKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PAo9BYh3pKI"
      },
      "outputs": [],
      "source": [
        "# loading CARE model\n",
        "model = keras.models.load_model(\n",
        "   MAIN_PATH+MODEL_PATH, custom_objects={\"psnr\": psnr,\"ssim\":ssim}, compile=False\n",
        ")\n",
        "prediction = model.predict(pretrain, batch_size = 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_percentile(img, pmin=0.1, pmax=99.9, clip = False):\n",
        "  eps=1e-20 # avoid zero division\n",
        "  mi = np.percentile(img,pmin,axis=None,keepdims=True)\n",
        "  ma = np.percentile(img,pmax,axis=None,keepdims=True)\n",
        "  if clip == True: return np.clip((img - mi) / ( ma - mi + eps ), 0, 1)\n",
        "  return (img - mi) / ( ma - mi + eps )"
      ],
      "metadata": {
        "id": "JFDvCttkMi6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ssim = []\n",
        "val_psnr = []\n",
        "val_mse = []\n",
        "if True:\n",
        "  for i in range(len(val_data)):\n",
        "    gt = tf.convert_to_tensor([normalize0to1(ground_truth[i,...]),],dtype=tf.float32)\n",
        "    # pred = tf.convert_to_tensor([normalize0to1(final_prediction[i,...]),],dtype=tf.float32)\n",
        "    raw = tf.convert_to_tensor([normalize0to1(input[i,...]),],dtype=tf.float32)\n",
        "\n",
        "    val_ssim.append(ssim(gt, raw).numpy()[0])\n",
        "    val_psnr.append(psnr(gt, raw).numpy()[0])\n",
        "    val_mse.append(mse(gt, raw))\n",
        "    # print(i, \"ssim, psnr, mse of gt vs pred: \",ssim(gt, pred).numpy()[0],psnr(gt, pred).numpy()[0],mse(gt, pred))\n",
        "    print(i, \"ssim, psnr, mse of gt vs raw: \",ssim(gt, raw).numpy()[0],psnr(gt, raw).numpy()[0],mse(gt, raw))\n",
        "    # eval = [normalize0to1(raw.numpy()[0,192:321,192:321,0]), normalize0to1(pred.numpy()[0,192:321,192:321,0]), normalize0to1(gt.numpy()[0,192:321,192:321,0])]\n",
        "    eval = [raw.numpy()[0,...,0], raw.numpy()[0,...,0], gt.numpy()[0,...,0]]\n",
        "    # # eval = [(m) for m in eval]\n",
        "    plotThree(eval, 'val, pred, gt', hist=False)\n",
        "    plotThree(eval, 'val, pred, gt', hist=True)\n",
        "    print(\"END====================================\")\n",
        "    print(\"\")\n",
        "\n",
        "  average_val_ssim = np.average(val_ssim)\n",
        "  average_val_psnr = np.average(val_psnr)\n",
        "  average_val_mse = np.average(val_mse)"
      ],
      "metadata": {
        "id": "SA3lDdpzbjc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQMctPvVFx8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ca81211-fe33-431e-962d-ee8e21775448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.26186514 17.286362 0.019016856\n"
          ]
        }
      ],
      "source": [
        "print(average_val_ssim,average_val_psnr,average_val_mse)\n",
        "#print(np.shape(prediction))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cycleGAN loading weights\n",
        "model = CycleGan(\n",
        "    generator_G=gen_G, generator_F=gen_F, discriminator_X=disc_X, discriminator_Y=disc_Y\n",
        ")\n",
        "model.built = True\n",
        "model.load_weights(MAIN_PATH+MODEL_PATH)\n",
        "prediction = model.gen_G.predict(pretrain, batch_size = 1)"
      ],
      "metadata": {
        "id": "5WAJ3Tjzcksa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSDOdn0EiB_v",
        "outputId": "b83fea38-812a-4ac6-cee5-52f9d02db310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(34, 512, 512, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_size_prediction = []\n",
        "for i in range(np.shape(input)[0]):\n",
        "  n = int((512-slide)/(patch-slide))**2\n",
        "  # print(\"i, n, i*n, i*(n+1)\",i, n, i*n, i*(n+1))\n",
        "  full_size_prediction.append(merge_patches(prediction[i*n:(i+1)*(n),...,0], 512, patch, slide))"
      ],
      "metadata": {
        "id": "FOTUlSFvKK1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "822cac9b-184f-4cbc-8913-add43119de25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n",
            "merging patches, img shape:  (1, 512, 512)\n",
            "(1, 512, 512)\n",
            "(1, 1, 512, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_prediction = expandLastDim(full_size_prediction)\n",
        "print(np.shape(final_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08if3YTfM5Pp",
        "outputId": "ac00c0de-5b0a-464a-cf9c-9dbc167f66b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(34, 512, 512, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0-Ug6DkaazL"
      },
      "outputs": [],
      "source": [
        "# TODO: as our data is normalized from -1 to 1, SSIM is quite off. Implement normalization 0 to 1 before calculating SSIM\n",
        "\n",
        "# no shifting\n",
        "val_ssim = []\n",
        "val_psnr = []\n",
        "val_mse = []\n",
        "if True:\n",
        "  for i in range(len(val_data)):\n",
        "    gt = tf.convert_to_tensor([normalize0to1(ground_truth[i,...]),],dtype=tf.float32)\n",
        "    pred = tf.convert_to_tensor([normalize0to1(final_prediction[i,...]),],dtype=tf.float32)\n",
        "    raw = tf.convert_to_tensor([normalize0to1(input[i,...]),],dtype=tf.float32)\n",
        "\n",
        "    val_ssim.append(ssim(gt, pred).numpy()[0])\n",
        "    val_psnr.append(psnr(gt, pred).numpy()[0])\n",
        "    val_mse.append(mse(gt, pred))\n",
        "    print(i, \"ssim, psnr, mse of gt vs pred: \",ssim(gt, pred).numpy()[0],psnr(gt, pred).numpy()[0],mse(gt, pred))\n",
        "    print(i, \"ssim, psnr, mse of gt vs raw: \",ssim(gt, raw).numpy()[0],psnr(gt, raw).numpy()[0],mse(gt, raw))\n",
        "    # eval = [normalize0to1(raw.numpy()[0,192:321,192:321,0]), normalize0to1(pred.numpy()[0,192:321,192:321,0]), normalize0to1(gt.numpy()[0,192:321,192:321,0])]\n",
        "    eval = [raw.numpy()[0,...,0], pred.numpy()[0,...,0], gt.numpy()[0,...,0]]\n",
        "    # eval = [(m) for m in eval]\n",
        "    plotThree(eval, 'val, pred, gt', hist=False)\n",
        "    # plotThree(eval, 'val, pred, gt', hist=True)\n",
        "    print(\"END====================================\")\n",
        "    print(\"\")\n",
        "\n",
        "  average_val_ssim = np.average(val_ssim)\n",
        "  average_val_psnr = np.average(val_psnr)\n",
        "  average_val_mse = np.average(val_mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXsB-7_47Te7"
      },
      "outputs": [],
      "source": [
        "# # perform prediction and create stacks of result array of raw, pred, gt\n",
        "# # TEST VERSION: shift mean of prediction to match gt mean, clip below 0\n",
        "# val_ssim = []\n",
        "# val_psnr = []\n",
        "# val_mse = []\n",
        "# if False:\n",
        "#   for i in range(len(val_data)):\n",
        "#     pred = final_prediction[i,...]\n",
        "#     gt = ground_truth[i,...]\n",
        "#     print(np.mean(pred),np.mean(gt))\n",
        "#     mean_diff = np.mean(pred) - np.mean(gt)\n",
        "#     print(\"mean_diff\",mean_diff)\n",
        "#     pred = pred - mean_diff\n",
        "#     print(\"mode after sub\", np.mean(pred),np.mean(gt))\n",
        "#     pred = np.clip(pred, 0.0,1.0)\n",
        "#     print(\"mode after clip\", np.mean(pred),np.mean(gt))\n",
        "#     gt = tf.convert_to_tensor([gt,],dtype=tf.float32)\n",
        "#     pred = tf.convert_to_tensor([pred,],dtype=tf.float32)\n",
        "#     raw = tf.convert_to_tensor([input[i,...],],dtype=tf.float32)\n",
        "\n",
        "#     val_ssim.append(ssim(gt, pred).numpy()[0])\n",
        "#     val_psnr.append(psnr(gt, pred).numpy()[0])\n",
        "#     val_mse.append(mse(gt, pred))\n",
        "#     print(i, \"ssim, psnr, mse of gt vs pred: \",ssim(gt, pred).numpy()[0],psnr(gt, pred).numpy()[0],mse(gt, pred))\n",
        "#     print(i, \"ssim, psnr, mse of gt vs raw: \",ssim(gt, raw).numpy()[0],psnr(gt, raw).numpy()[0],mse(gt, raw))\n",
        "#     eval = [raw.numpy()[0,...,0], pred.numpy()[0,...,0], gt.numpy()[0,...,0]]\n",
        "#     # eval = [(m) for m in eval]\n",
        "#     plotThree(eval, 'val, pred, gt', hist=False)\n",
        "#     plotThree(eval, 'val, pred, gt', hist=True)\n",
        "#     print(\"END====================================\")\n",
        "#     print(\"\")\n",
        "\n",
        "#   average_val_ssim = np.average(val_ssim)\n",
        "#   average_val_psnr = np.average(val_psnr)\n",
        "#   average_val_mse = np.average(val_mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBNlZ7gLyovO"
      },
      "outputs": [],
      "source": [
        "#validation\n",
        "# stack_ranges = [[0,16],[16,34]]\n",
        "# key_name = [\"20210420_ROI3_512_shifted\",\"20210421_ROI5_512_shifted\"]\n",
        "\n",
        "#train\n",
        "# stack_ranges = [[0,21],[21,52],[52,73],[73,78],[78,86],[86,93],[93,110],[110,134],[134,143],[143,152],[152,180],[180,214],[214,238]]\n",
        "# key_name = [\"20210420_ROI2_512_shifted\",\"20210421_ROI4_512_shifted\",\"20210426_ROI1_512_shifted\",\"20210426_ROI2_512_shifted\",\"20210426_ROI3_512_shifted\",\"20210426_ROI4_512_shifted\",\"20210505_ROI1_512_shifted\",\"20210505_ROI2_512_shifted\",\"20210505_ROI3_512_shifted\",\"20210505_ROI4_512_shifted\",\"20210526_ROI3_512_shifted\",\"20210615_ROI1_512_shifted\",\"20210622_ROI4_512_shifted\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(MODEL_NAME)"
      ],
      "metadata": {
        "id": "qoxOERXCjm8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFAOGt0f3AF-"
      },
      "outputs": [],
      "source": [
        "#validation\n",
        "stack_ranges = [[0,16],[16,34]]\n",
        "key_name = [\"20210420_ROI3_512_shifted\",\"20210421_ROI5_512_shifted\"]\n",
        "\n",
        "# # saving validation stacks into .mat files\n",
        "os.chdir(MAIN_PATH+'/validation/1009/')\n",
        "for i in range(np.shape(stack_ranges)[0]):\n",
        "    image_mat = []\n",
        "    for n in range(stack_ranges[i][0],stack_ranges[i][1]):\n",
        "        result = [input[n], final_prediction[n], ground_truth[n]]\n",
        "        result = [normalize0to1(m) for m in result]\n",
        "        result = np.stack(result)\n",
        "        result = np.clip(255 * result, 0, 255).astype('uint8')\n",
        "        image_mat.append([result[0],result[1],result[2]])\n",
        "    scipy.io.savemat(\"NADH_\"+MODEL_NAME + '_'+ key_name[i] +'_val.mat', {'images': image_mat})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#train\n",
        "stack_ranges = [[0,21],[21,52],[52,73],[73,78],[78,86],[86,93],[93,110],[110,134],[134,143],[143,152],[152,180],[180,214],[214,238]]\n",
        "key_name = [\"20210420_ROI2_512_shifted\",\"20210421_ROI4_512_shifted\",\"20210426_ROI1_512_shifted\",\"20210426_ROI2_512_shifted\",\"20210426_ROI3_512_shifted\",\"20210426_ROI4_512_shifted\",\"20210505_ROI1_512_shifted\",\"20210505_ROI2_512_shifted\",\"20210505_ROI3_512_shifted\",\"20210505_ROI4_512_shifted\",\"20210526_ROI3_512_shifted\",\"20210615_ROI1_512_shifted\",\"20210622_ROI4_512_shifted\"]\n",
        "\n",
        "# # saving validation stacks into .mat files\n",
        "os.chdir(MAIN_PATH+'/train/1009/')\n",
        "for i in range(np.shape(stack_ranges)[0]):\n",
        "    image_mat = []\n",
        "    for n in range(stack_ranges[i][0],stack_ranges[i][1]):\n",
        "        result = [input[n], final_prediction[n], ground_truth[n]]\n",
        "        result = [normalize0to1(m) for m in result]\n",
        "        result = np.stack(result)\n",
        "        result = np.clip(255 * result, 0, 255).astype('uint8')\n",
        "        image_mat.append([result[0],result[1],result[2]])\n",
        "    scipy.io.savemat(\"NADH_\"+MODEL_NAME + '_'+ key_name[i] +'_val.mat', {'images': image_mat})"
      ],
      "metadata": {
        "id": "JINGgsy_XUo2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}